---
title: "Generalized Linear Models"
date: 2019-10-20
tags: [glm, logistic regression, poisson regression, stat]
---



## Linear Models Limitations<br>
{: style="text-align: center;"}

A general linear model assumes that the response variable(<img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;Y" title="Y" />) takes continuous values and that the error terms of the model are normally distributed with zero mean and constant variance
{: style="text-align: justify;"}
<img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\varepsilon&space;\sim&space;N(0,1)" title="\varepsilon \sim N(0,1)" />
{: style="text-align: center;"}

Although linear models provide a very useful framework, there are some situations where they are not appropriate and the relationship in the data cannot adequately be summarized by a simple linear equation, for two main reasons:<br>
{: style="text-align: justify;"}

1.&nbsp;&nbsp;&nbsp;The dependent variable of interest may have a non-continuous distribution (i.e. the range value of the dependent variable is restricted).<br>
2.&nbsp;&nbsp;&nbsp;The variance may be not constant.<br>
{: style="text-align: justify;"}

For instance, when considering a Binomial distribution or a Poisson distribution the variance is a function of the expected value and therefore, for construction, it is not constant.<br>
{: style="text-align: justify;"}

<img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;X&space;\sim&space;B(n,p)\rightarrow&space;E(X)&space;=&space;n&space;,&space;Var(X)=np(1-p)" title="X \sim B(n,p)\rightarrow E(X) = n , Var(X)=np(1-p)" /><br>
{: style="text-align: center;"}
<img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;X&space;\sim&space;P(\lambda)\rightarrow&space;E(X)&space;=&space;Var(X)=\lambda" title="X \sim P(\lambda)\rightarrow E(X) = Var(X)=\lambda" />
{: style="text-align: center;"}

Generalized linear models extend the general linear model framework to address both of these issues.<br>
{: style="text-align: justify;"}


## GLMs Characteristics<br>
{: style="text-align: center;"}

A generalized linear model is determined by three components:
{: style="text-align: justify;"}
* the **distribution of the target variable**, which is assumed to be belong to the exponential family, a class of probability distributions which covers a large number of distributions such as Bernoulli, binomial, Poisson and also Gaussian distribution
{: style="text-align: justify;"}
* the **systematic component**: any set of *X = (X<sub>1</sub>, X<sub>2</sub>, ... ,X<sub>k</sub>)* explanatory variables
{: style="text-align: justify;"}
* the **link function**, which transforms the non-linear relationship between the expected value of the target variable and the predictors in a linear relation so that the target variable can be modeled with linear regression.
{: style="text-align: justify;"}

This article is focused on GLMs used to model *binary* or *count* data (i.e. when the response variables follows the binomial or Poisson distribution).<br>
{: style="text-align: justify;"}

The table below describes those models’ structures<br>
{: style="text-align: justify;"}

![image-center]({{ site.url }}{{ site.baseurl }}/images/2019-10-20-glm/table.jpg)
{: .align-center}

The multinomial regression model is an extension of the logistic regression model and it is used when the target is a categorical variable having multiple classes. 
{: style="text-align: justify;"}

# Logistic Regression<br>
{: style="text-align: center;"}

Logistic regression is the appropriate regression analysis to conduct when the target variable is dichotomous (i.e. it is a categorical variable having two classes 0 and 1).<br>
{: style="text-align: justify;"}
For instance, logistic regression allows to answer a question such as:
{: style="text-align: justify;"}
*How does the probability of heart disease (yes vs. no) change for every additional year of age of a person and for every pack of cigarettes smoked per day?*<br>
{: style="text-align: justify;"}

Logistic regression allows to predict the class of the target variable for a new observation by estimating the ***probability*** that that observation falls into the class 1 based on one or more independent variables (that can be either continuous or categorical).<br>
{: style="text-align: justify;"}

Note that logistic regression does not return directly the class of observations. It allows us to estimate the probability (p) of class membership and then, on the basis of a given threshold, conclude that observations having a probability higher than the threshold will belong to the class 1.
{: style="text-align: justify;"}
{: .notice--danger}

## Logistic Regression Assumptions<br>
{: style="text-align: center;"}

&nbsp;&nbsp;&nbsp;1.&nbsp;&nbsp;&nbsp;&nbsp;Logistic regression requires the dependent variable to follow a binomial distribution <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;Y&space;\sim&space;B(n,p)" title="Y \sim B(n,p)" /><br>
{: style="text-align: justify;"}

&nbsp;&nbsp;&nbsp;2.&nbsp;&nbsp;&nbsp;&nbsp;Independence of observations<br>
This means that each observation is independent of the other observations; that is, one observation cannot provide any information on another observation.<br>
{: style="text-align: justify;"}

&nbsp;&nbsp;&nbsp;3.&nbsp;&nbsp;&nbsp;&nbsp;No multi-collinearity<br>
The independent variables should be independent of each other.<br>
{: style="text-align: justify;"}

&nbsp;&nbsp;&nbsp;4.&nbsp;&nbsp;&nbsp;&nbsp;Equidispersion in data<br>
{: style="text-align: justify;"}


## Logistic Regression Link Function<br>
{: style="text-align: center;"}
Since the objective is to estimate a probability (i.e. a continuous but bounded value), model parameters must be estimated such as two conditions are met:<br>
1.&nbsp;&nbsp;&nbsp;the estimated output cannot be negative (since it is a probability and it cannot be negative).<br>
For that, the general linear model is modified by putting the linear equation in exponential form.<br>
2.&nbsp;&nbsp;&nbsp;the estimated output can never be grater than 1 (since the probability cannot be greater than 1).<br> For that, the model output is divided by something bigger than itself.<br>
{: style="text-align: justify;"}

Let <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;Y" title="Y" /> be the binary outcome variable indicating failure {0} or success {1}.<br>
{: style="text-align: justify;"}
Let <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;X" title="X" /> a vector containing a set of <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;k" title="k" /> predictor variables.<br>
{: style="text-align: justify;"}
In a logistic regression model, the probability of <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;Y" title="Y" /> to be 1, <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;p&space;=&space;P(Y=1)" title="p = P(Y=1)" />, is modelled by the following equation
{: style="text-align: justify;"}

<img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;P(Y=1)=p=\frac{e^{\beta_{0}&space;&plus;&space;\beta&space;X}}{1&plus;e^{\beta_{0}&space;&plus;&space;\beta&space;X}}" title="P(Y=1)=p=\frac{e^{\beta_{0} + \beta X}}{1+e^{\beta_{0} + \beta X}}" />
{: style="text-align: center;"}


Note that <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;p&space;=&space;P(Y=1)" title="p = P(Y=1)" /> is nonlinear, which means that the effect of a change in <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\beta_{k}" title="\beta_{k}" /> will depend not only on <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;X_{k}" title="X_{k}" /> (as in the classical linear regression), but also on the value of <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;X_{k}" title="X_{k}" />.
{: style="text-align: justify;"}

Even if it results a non-linear association, it is possible to model it in a linear way through a logarithmic transformation on the outcome variable probability, called **logit**, as follows
{: style="text-align: justify;"}

<img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;logit(p)&space;=&space;log(\frac{p}{1-p})=\beta_{0}&space;&plus;&space;\beta&space;X" title="logit(p) = log(\frac{p}{1-p})=\beta_{0} + \beta X" />
{: style="text-align: center;"}
where the term <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\frac{p}{1-p}" title="\frac{p}{1-p}" /> is the ODDS RATIO which represents the ratio of the probability of success over the probability of failure. 
That is to say that the probability of success is 0.50, then the odds of success is 1 to 1.
{: style="text-align: justify;"}

The logit transformation allows to link the expected value of the response variable to a linear combination of predictors.<br>
{: style="text-align: justify;"}

Model’s parameters are estimated from the logit function via maximum likelihood method.<br>
{: style="text-align: justify;"}


## How to interpret logistic regression parameters<br>
{: style="text-align: center;"}

This task is quite more complex than for general linear regression, since model parameter are estimated on the scale of the model link function, i.e. the logit function<br> 
{: style="text-align: justify;"}

<img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;logit(p)&space;=&space;log(\frac{p}{1-p})=\beta_{0}&space;&plus;&space;\beta&space;X" title="logit(p) = log(\frac{p}{1-p})=\beta_{0} + \beta X" />
{: style="text-align: center;"}

To interpret model results, we need to come back to the scale of probabilities, so we need to calculate the exponential value of each model parameter <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\large&space;e^{\beta_i}" title="\large e^{\beta_i}" />.<br>
{: style="text-align: justify;"}

The coefficient <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\large&space;i}" title="i" /> means that for one unite increase in the <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\large&space;X_i" title="X_i" />  variable, the odds to belong to the class 1 changes by a factor equal to <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\large&space;e^{\beta_i}" title="\large e^{\beta_i}" />.<br>
{: style="text-align: justify;"}

The **sign** of the coefficient indicates whether the chance an observation to belong to the class 1 increases or decreases for the predictor <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\large&space;X_i" title="X_i" />.<br> 
{: style="text-align: justify;"}

The **magnitude** of the coefficient implies that for every one unit increase in in <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\large&space;X_i" title="X_i" /> , the odds to belong to the class 1 changes by a factor equal to <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\large&space;e^{\beta_i}" title="\large e^{\beta_i}" /> on average.<br>
{: style="text-align: justify;"}

For example, if we are running a logistic regression to investigate how glucose level affects the probability to become diabetic and the regression coefficient for glucose is 0.052, it means that one unit increase in the glucose concentration will increase the likelihood of being diabetes-positive by <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;&space;e^{0.052}" title="e^{0.052}" /> times.<br>
{: .notice--info}
{: style="text-align: justify;"}


## Using the Model to make Predictions<br>
{: style="text-align: center;"}

Once the logistic model estimated, the procedure to make prediction about new observations is as follow:<br>
{: style="text-align: justify;"}
1.&nbsp;&nbsp;&nbsp;Predict the class membership probabilities of each observation based on predictor variables<br>
2.&nbsp;&nbsp;&nbsp;Assign the observations to the class with highest probability score (i.e above 0.5)<br>
{: style="text-align: justify;"}

## Assessing Model Accuracy
{: style="text-align: center;"}
The most commonly tool used to evaluate classification models is the **Confusion Matrix**.<br><br>
In a confusion matrix, the actual and predicted values are organized in a tabular format as below<br>
{: style="text-align: justify;"}

![image-center]({{ site.url }}{{ site.baseurl }}/images/2019-10-20-glm/confusionMatrix.jpg){: .align-center}

In this case, a total of 150 predictions have been made by using the model.<br>
{: style="text-align: justify;"}
Out of those 150 cases, 100 observations have been predicted to belong to class 1 and 50 to the class 0. In reality, 90 observation belong to the class 1 and 45 to the class 0.<br>
{: style="text-align: justify;"}
From this matrix, different metrics can be derived, such as:<br>
{: style="text-align: justify;"}
 - <span style = "font-family: times, serif; font-size:16pt; font-style:italic; color: #1512DE; text-align: center;">True Positive (TP):</span> the model predicts class 1 and the observation actually belongs to the class 1 (90 cases)
 - <span style = "font-family: times, serif; font-size:16pt; font-style:italic; color: #1512DE; text-align: center;">True Negative (TP):</span> the model predicts class 0 and the observation actually belongs to the class 0 (45 cases)
 - <span style = "font-family: times, serif; font-size:16pt; font-style:italic; color: #1512DE; text-align: center;">False Positive (FP) (aka “Type I error”) :</span>  the model predicts class 1 but the observation actually belongs to the class 0 (10 cases)
- <span style = "font-family: times, serif; font-size:16pt; font-style:italic; color: #1512DE; text-align: center;">False Negative (FN) (aka “Type II error”) :</span>  the model predicts class 0 but the observation actually belongs to the class 1 (5 cases)
{: style="text-align: justify;"}

The <span style = "font-family: times, serif; font-size:16pt; font-style:italic; color: #1512DE; text-align: center;">Accuracy</span>  of the model can be evaluated as <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\frac{(TP&plus;TN)}{Total}" title="\frac{(TP+TN)}{Total}" /> which describes, overall, how often the model predicts correctly.<br>
{: style="text-align: justify;"}

Complementary to accuracy metric, there is the <span style = "font-family: times, serif; font-size:16pt; font-style:italic; color: #1512DE; text-align: center;">Total Error</span>  of the model <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\frac{(FP&plus;FN)}{Total}" title="\frac{(TP+TN)}{Total}" /> which quantifies how often the model makes a wrong prediction.
{: style="text-align: justify;"}

# Poisson Regression<br>
{: style="text-align: center;"}

Poisson regression is used for modelling the number of events that occur in a given time period or area.<br>
{: style="text-align: justify;"}
A Poisson regression is suitable when the target variable is a count variable that approximates the Poisson distribution. Thus, the possible values of <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;Y" title="Y" /> are the non-negative integers: 0, 1, 2 and so on.<br>
{: style="text-align: justify;"}
However, the Poisson distribution assumes that events are **rare** (as opposed to more common events which tend to be normally distributed).<br>
Therefore, Poisson regression is more suited to cases where the target variable takes small integer values.
{: style="text-align: justify;"}

*One example of an appropriate application of Poisson regression is a study the number of failures for a certain machine at various operating conditions*.<br>
{: style="text-align: justify;"}

Explanatory variables, <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;X&space;=&space;(X_{1}&space;,&space;X_{2}&space;,&space;...,&space;X_{k})" title="X = (X_{1} , X_{2} , ..., X_{k})" />, can be continuous or a combination of continuous and categorical variables.<br>
{: style="text-align: justify;"}

## Poisson Regression Assumptions<br>
{: style="text-align: center;"}

&nbsp;&nbsp;&nbsp;1.&nbsp;&nbsp;&nbsp;The dependent variable follows a Poisson distribution<br>
{: style="text-align: justify;"}
<img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;Y\sim&space;P(\lambda&space;)\rightarrow&space;E(Y)=&space;Var(Y)&space;=&space;\lambda" title="Y\sim P(\lambda )\rightarrow E(Y)= Var(Y) = \lambda" /><br>
{: style="text-align: center;"}
Furthermore, it is sometimes suggested that Poisson regression only be performed when the mean count is a small value.<br>
{: style="text-align: justify;"}
&nbsp;&nbsp;&nbsp;2.&nbsp;&nbsp;&nbsp;Independence of observations<br>
This means that each observation is independent of the other observations; that is, one observation cannot provide any information on another observation.<br>
{: style="text-align: justify;"}

&nbsp;&nbsp;&nbsp;3.&nbsp;&nbsp;&nbsp;The mean and variance of the model are identical.<br>
This is a consequence of Assumption 1 that there is a Poisson distribution. For a Poisson distribution the variance has the same value as the mean.<br>
{: style="text-align: justify;"}
If this assumption is satisfied, we have equidispersion.<br>
{: style="text-align: justify;"}
However, often this is not the case and the data is either **under-** or **overdispersed** with ove
rdispersion the more common problem.<br>
{: style="text-align: justify;"}

Overdispersion, can arise when one or more unobserved variables are contributing to the mean but are not included in the model. (If those variables were to be included in the regression, the variance would be reduced as the contribution to the residuals caused by their absence would be eliminated.)<br>
{: style="text-align: justify;"}

Equidispersion assumption can be assessedby plotting model’s residuals<br>
{: style="text-align: justify;"}

## Poisson Regression Link Function<br>
{: style="text-align: center;"}

Since the aim of a Poisson regression is to model the conditional mean <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;E(Y|X_{k})" title="E(Y|X_{k})" /> or 
or the average number of events <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\lambda" title="\lambda" />, and since this value has to be a positive integer, model parameters must be estimated such as to be sure that the estimated value <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;E(Y|X_{k})" title="E(Y|X_{k})" /> is always positive.<br>
{: style="text-align: justify;"}

For that, the general linear model is modified by putting the linear equation in exponential form.<br>
{: style="text-align: justify;"}
<img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;E(Y|X)&space;=&space;e^{\beta_{0}&space;&plus;\beta&space;X&space;}" title="E(Y|X) = e^{\beta_{0} +\beta X }" />
{: style="text-align: center;"}

Let <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;Y" title="Y" /> be a Poisson outcome variable indicating the number of times that a certain event occurs during a given time period, with <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;E(Y) = \lambda" />.<br>
{: style="text-align: justify;"}
Let <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;X" title="X" /> a vector containing a set of predictor variables.<br>
{: style="text-align: justify;"}

Then the Poisson regression of <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;Y" title="Y" /> on <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;X" title="X" /> estimates parameter values for <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\beta_{0},&space;\beta_{1},&space;...,&space;\beta_{k}" title="\beta_{0}, \beta_{1}, ..., \beta_{k}" />via maximum likelihood method of the log link function, which allows to link the expected value of the response variable to the linear combination of predictors.<br>
{: style="text-align: justify;"}

<img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;log(Y|X&space;)=log\lambda=&space;\beta&space;_{0}&space;&plus;&space;\beta&space;X" title="log(Y|X )=log\lambda= \beta _{0} + \beta X" />
{: style="text-align: center;"}


This logarithmic transformation on the outcome variable allows us to model a non-linear association in a linear way.<br>
{: style="text-align: justify;"}

Taking exponent on both sides of the equation returns the average number of time that a certain event occurs during a given time period <br>
{: style="text-align: justify;"}

<img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;E(Y|X&space;)=\lambda=&space;e^{\beta&space;_{0}&space;&plus;&space;\beta&space;X}" title="E(Y|X )=\lambda= e^{\beta _{0} + \beta X}" />
{: style="text-align: center;"}

## How to interpret Poisson regression parameters<br>
{: style="text-align: center;"}

After having carried out a Poisson regression, results have to be interpreted.<br>
The aim is to determine which of the independent variables (if any) have a statistically significant effect on the dependent variable.<br>
{: style="text-align: justify;"}

For that, we have to analyze the model parameters <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\beta_{0},&space;\beta_{1},&space;...,&space;\beta_{k}" title="\beta_{0}, \beta_{1}, ..., \beta_{k}" />.<br>
{: style="text-align: justify;"}

Since model parameter are estimated on the scale of the model link function, i.e. the log function, to interpret model results, we need to come back to the scale of response variable, so we need to calculate the exponential value of each model parameter.<br>
{: style="text-align: justify;"}

When the i independent predictor is a binary categorical variable, the parameter <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;e^{\beta_{k}}=\frac{&space;log\lambda_{group1}}{log\lambda_{group2}}&space;=&space;log\lambda_{group1}&space;-&space;log\lambda_{group2}" title="e^{\beta_{k}}=\frac{ log\lambda_{group1}}{log\lambda_{group2}} = log\lambda_{group1} - log\lambda_{group2}" /> represents the difference of the number of times an event occurs in one group versus another (e.g. number of car accidents amongst women and men).
Therefore, if <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\beta_{k}" title="\beta_{k}" /> is positive we can say that the <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;E(Y)" title="E(Y)" /> is <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;e^{\beta_{k}}" title="e^{\beta_{k}}" /> times larger for the group 1 than for the group 2.<br>
{: .notice--info}
{: style="text-align: justify;"}

When the i predictor is continuous, if <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;\beta_{k}" title="\beta_{k}" /> is positive, we can say that the <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;E(Y)" title="E(Y)" /> is <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;e^{\beta_{k}}" title="e^{\beta_{k}}" /> times larger when the variable <img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;X_{i}}" title="X_{i}}" /> increases by one unit (<img src="https://latex.codecogs.com/svg.latex?\fn_cs&space;e^{\beta_{k}}&space;=\frac{&space;log\lambda_{X&plus;1}}{log\lambda_{X}}&space;=&space;log\lambda_{X&plus;1}&space;-&space;log\lambda_{X}" title="e^{\beta_{k}} =\frac{ log\lambda_{X+1}}{log\lambda_{X}} = log\lambda_{X+1} - log\lambda_{X}" />).<br>
{: .notice--info}
{: style="text-align: justify;"}







